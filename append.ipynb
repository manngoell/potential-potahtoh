{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d7d5fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mangoel\\AppData\\Local\\Temp\\ipykernel_26092\\2950811003.py:9: DtypeWarning: Columns (5,9,11,13,15,17,19,21,23,25,27,29,31,33,35,37,39,41,43,45,47,49,51,53,55,57,59,61,63,65,67,69,71,73,75,77,79,81,83,85,87,89,91,93,95,97,99,101,103,105,107,109,111,113,115,117,119,121,123,125,127,129,131,133,135,137,139,141,143,145,147,149,151,153,155,157,159,161,163,165,167,169,171,173,175,177,179,181,183,185,187,189,191,193,195,197,199,201,203,205,207,209,211,213,215,217) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns to remove: ['2025-09-23 15:30 - Condition/Validity', '2025-09-23 15:15 - Condition/Validity', '2025-09-23 15:00 - Condition/Validity', '2025-09-23 14:45 - Condition/Validity', '2025-09-23 14:30 - Condition/Validity', '2025-09-23 14:15 - Condition/Validity', '2025-09-23 14:00 - Condition/Validity', '2025-09-23 13:45 - Condition/Validity', '2025-09-23 13:30 - Condition/Validity', '2025-09-23 13:15 - Condition/Validity', '2025-09-23 13:00 - Condition/Validity', '2025-09-23 12:45 - Condition/Validity', '2025-09-23 12:30 - Condition/Validity', '2025-09-23 12:15 - Condition/Validity', '2025-09-23 12:00 - Condition/Validity', '2025-09-23 11:45 - Condition/Validity', '2025-09-23 11:30 - Condition/Validity', '2025-09-23 11:15 - Condition/Validity', '2025-09-23 11:00 - Condition/Validity', '2025-09-23 10:45 - Condition/Validity', '2025-09-23 10:30 - Condition/Validity', '2025-09-23 10:15 - Condition/Validity', '2025-09-23 10:00 - Condition/Validity', '2025-09-23 09:45 - Condition/Validity', '2025-09-23 09:30 - Condition/Validity', '2025-09-23 09:15 - Condition/Validity', '2025-09-23 09:00 - Condition/Validity', '2025-09-23 08:45 - Condition/Validity', '2025-09-23 08:30 - Condition/Validity', '2025-09-23 08:15 - Condition/Validity', '2025-09-23 08:00 - Condition/Validity', '2025-09-23 07:45 - Condition/Validity', '2025-09-23 07:30 - Condition/Validity', '2025-09-23 07:15 - Condition/Validity', '2025-09-23 07:00 - Condition/Validity', '2025-09-23 06:45 - Condition/Validity', '2025-09-23 06:30 - Condition/Validity', '2025-09-23 06:15 - Condition/Validity', '2025-09-23 06:00 - Condition/Validity', '2025-09-23 05:45 - Condition/Validity', '2025-09-23 05:30 - Condition/Validity', '2025-09-23 05:15 - Condition/Validity', '2025-09-23 05:00 - Condition/Validity', '2025-09-23 04:45 - Condition/Validity', '2025-09-23 04:30 - Condition/Validity', '2025-09-23 04:15 - Condition/Validity', '2025-09-23 04:00 - Condition/Validity', '2025-09-23 03:45 - Condition/Validity', '2025-09-23 03:30 - Condition/Validity', '2025-09-23 03:15 - Condition/Validity', '2025-09-23 03:00 - Condition/Validity', '2025-09-23 02:45 - Condition/Validity', '2025-09-23 02:30 - Condition/Validity', '2025-09-23 02:15 - Condition/Validity', '2025-09-23 02:00 - Condition/Validity', '2025-09-23 01:45 - Condition/Validity', '2025-09-23 01:30 - Condition/Validity', '2025-09-23 01:15 - Condition/Validity', '2025-09-23 01:00 - Condition/Validity', '2025-09-23 00:45 - Condition/Validity', '2025-09-23 00:30 - Condition/Validity', '2025-09-23 00:15 - Condition/Validity', '2025-09-23 00:00 - Condition/Validity', '2025-09-23 15:45 - Condition/Validity', '2025-09-22 23:45 - Condition/Validity', '2025-09-22 23:30 - Condition/Validity', '2025-09-22 23:15 - Condition/Validity', '2025-09-22 23:00 - Condition/Validity', '2025-09-22 22:45 - Condition/Validity', '2025-09-22 22:30 - Condition/Validity', '2025-09-22 22:15 - Condition/Validity', '2025-09-22 22:00 - Condition/Validity', '2025-09-22 21:45 - Condition/Validity', '2025-09-22 21:30 - Condition/Validity', '2025-09-22 21:15 - Condition/Validity', '2025-09-22 21:00 - Condition/Validity', '2025-09-22 20:45 - Condition/Validity', '2025-09-22 20:30 - Condition/Validity', '2025-09-22 20:15 - Condition/Validity', '2025-09-22 20:00 - Condition/Validity', '2025-09-22 19:45 - Condition/Validity', '2025-09-22 19:30 - Condition/Validity', '2025-09-22 19:15 - Condition/Validity', '2025-09-22 19:00 - Condition/Validity', '2025-09-22 18:45 - Condition/Validity', '2025-09-22 18:30 - Condition/Validity', '2025-09-22 18:15 - Condition/Validity', '2025-09-22 18:00 - Condition/Validity', '2025-09-22 17:45 - Condition/Validity', '2025-09-22 17:30 - Condition/Validity', '2025-09-22 17:15 - Condition/Validity', '2025-09-22 17:00 - Condition/Validity', '2025-09-22 16:45 - Condition/Validity', '2025-09-22 16:30 - Condition/Validity', '2025-09-22 16:15 - Condition/Validity', '2025-09-22 16:00 - Condition/Validity', '2025-09-23 16:00 - Condition/Validity', '2025-09-23 16:15 - Condition/Validity', '2025-09-23 17:00 - Condition/Validity', '2025-09-23 16:45 - Condition/Validity', '2025-09-23 16:30 - Condition/Validity', '2025-09-22 15:45 - Condition/Validity', '2025-09-22 15:30 - Condition/Validity', '2025-09-22 15:15 - Condition/Validity', '2025-09-22 15:00 - Condition/Validity', '2025-09-22 14:45 - Condition/Validity']\n",
      "Cleaned file saved as: C:\\Users\\mangoel\\OneDrive - Ciena Corporation\\WLP_automation_folder\\Cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "#---- This cell will remove the blank columns between two valued columns\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import re  # Regular expressions module\n",
    "\n",
    "# --- File paths ---\n",
    "input_file = r\"C:\\Users\\mangoel\\OneDrive - Ciena Corporation\\WLP_automation_folder\\Appended.csv\"\n",
    "output_file = r\"C:\\Users\\mangoel\\OneDrive - Ciena Corporation\\WLP_automation_folder\\Cleaned.csv\"\n",
    "\n",
    "# --- Read the CSV file into a DataFrame ---\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# --- Identify columns to drop ---\n",
    "# Pattern matches \"YYYY-MM-DD HH:MM - Condition/Validity\"\n",
    "pattern = r\"\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2} - Condition/Validity\"\n",
    "\n",
    "# Find all columns matching the pattern\n",
    "columns_to_drop = [col for col in df.columns if re.fullmatch(pattern, str(col))]\n",
    "\n",
    "print(f\"Columns to remove: {columns_to_drop}\")  # Display which columns will be removed\n",
    "\n",
    "# --- Drop the identified columns ---\n",
    "df.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "# --- Save the cleaned DataFrame back to CSV ---\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Cleaned file saved as: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8473a6ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mangoel\\AppData\\Local\\Temp\\ipykernel_26092\\2047778764.py:7: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 'MAX' column added successfully at column F in the same Cleaned.csv file.\n",
      "\n",
      "Preview of the first 5 rows:\n",
      "        Network element Measurement point     Parameter  Location Direction  \\\n",
      "0   CLT-BLKL-NEC-R-C422     ETH100G-1-1-2  UTLAVG-E (%)  NEAR_END   RECEIVE   \n",
      "1  HSN_TGKK_HEM_T_C1516     ETH100G-1-1-2  UTLAVG-E (%)  NEAR_END  TRANSMIT   \n",
      "2  HSN_TGKK_HEM_T_C1516     ETH100G-1-1-2  UTLAVG-E (%)  NEAR_END   RECEIVE   \n",
      "3   HBL_TGKR_DJB_R_C012     ETH100G-1-1-2  UTLAVG-E (%)  NEAR_END   RECEIVE   \n",
      "4   GUO-TGTN-MMR-R-C426     ETH100G-1-1-2  UTLAVG-E (%)  NEAR_END  TRANSMIT   \n",
      "\n",
      "    MAX Current  Current - Condition/Validity  Current-time  2025-09-23 15:30  \\\n",
      "0  18.0       -                           NaN           NaN              10.0   \n",
      "1   1.0       -                           NaN           NaN               1.0   \n",
      "2   3.0       -                           NaN           NaN               1.0   \n",
      "3   1.0       -                           NaN           NaN               1.0   \n",
      "4   1.0       -                           NaN           NaN               NaN   \n",
      "\n",
      "   ...  22-09-2025 17:45  22-09-2025 17:30  22-09-2025 17:15  \\\n",
      "0  ...               NaN               NaN               NaN   \n",
      "1  ...               NaN               NaN               NaN   \n",
      "2  ...               NaN               NaN               NaN   \n",
      "3  ...               NaN               NaN               NaN   \n",
      "4  ...               NaN               NaN               NaN   \n",
      "\n",
      "   22-09-2025 17:00  22-09-2025 16:45  22-09-2025 16:30  22-09-2025 16:15  \\\n",
      "0               NaN               NaN               NaN               NaN   \n",
      "1               NaN               NaN               NaN               NaN   \n",
      "2               NaN               NaN               NaN               NaN   \n",
      "3               NaN               NaN               NaN               NaN   \n",
      "4               NaN               NaN               NaN               NaN   \n",
      "\n",
      "   22-09-2025 16:00  22-09-2025 15:45  22-09-2025 15:30  \n",
      "0               NaN               NaN               NaN  \n",
      "1               NaN               NaN               NaN  \n",
      "2               NaN               NaN               NaN  \n",
      "3               NaN               NaN               NaN  \n",
      "4               NaN               NaN               NaN  \n",
      "\n",
      "[5 rows x 210 columns]\n"
     ]
    }
   ],
   "source": [
    "# This cell will add the MAX coulmn containing the max values of each row.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# --- File path (same input & output) ---\n",
    "file_path = r\"C:\\Users\\mangoel\\OneDrive - Ciena Corporation\\WLP_automation_folder\\Cleaned.csv\"\n",
    "\n",
    "# --- Step 1: Read the CSV file ---\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# --- Step 2: Calculate MAX value for each row ---\n",
    "# Convert all values to numeric (non-numeric values become NaN)\n",
    "df_numeric = df.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Compute row-wise maximum values\n",
    "df['MAX'] = df_numeric.max(axis=1)\n",
    "\n",
    "# --- Step 3: Move 'MAX' column to position 6 (column F) ---\n",
    "cols = list(df.columns)\n",
    "max_col = cols.pop(cols.index('MAX'))  # Remove 'MAX' from the end\n",
    "cols.insert(5, max_col)                # Insert at position 6 (index 5)\n",
    "df = df[cols]                          # Reorder columns\n",
    "\n",
    "# --- Step 4: Save the updated file (overwrite the same file) ---\n",
    "df.to_csv(file_path, index=False)\n",
    "\n",
    "print(\"✅ 'MAX' column added successfully at column F in the same Cleaned.csv file.\")\n",
    "print(\"\\nPreview of the first 5 rows:\")\n",
    "print(df.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
